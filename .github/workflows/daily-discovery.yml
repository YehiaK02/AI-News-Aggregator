name: Daily AI News Discovery

on:
  schedule:
    # Runs at 6:00 AM UTC (8:00 AM Cairo time)
    - cron: '0 6 * * *'
  
  # Allow manual trigger
  workflow_dispatch:

# Prevent parallel runs
concurrency:
  group: article-processing
  cancel-in-progress: true

jobs:
  discover-and-process:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Run article discovery workflow
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
          GOOGLE_SHEETS_CREDENTIALS: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
          GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SHEET_ID }}
        working-directory: src
        run: |
          python main.py
      
      - name: Workflow Summary
        if: always()
        run: |
          echo "### AI News Aggregator - Workflow Summary ðŸ“Š" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Execution Time:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check your Google Sheet for processed articles!" >> $GITHUB_STEP_SUMMARY
